{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "sns.set_context(\"talk\", font_scale=1.0, rc={\"font.family\": \"serif\", \"font.serif\": [\"Computer Modern Serif\"]})\n",
    "\n",
    "fig_size = (14,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_networks = pathlib.Path(\"../model_outputs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get basic compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_datasets = [\"all_files\"]\n",
    "list_of_losses = [\"rmse\"]\n",
    "pytorch_architectures_names = [    \n",
    "    \"Unet\",\n",
    "    \"Unet++\",\n",
    "    \"Deeplabv3\",\n",
    "    \"Deeplabv3+\",\n",
    "    \"FPNet\",\n",
    "    \"PSPNet\",\n",
    "    \"MANet\",\n",
    "    \"LinkNet\",\n",
    "    \"Pan\",\n",
    "    ]\n",
    "pytorch_architectures = [    \n",
    "    \"unet\",\n",
    "    \"unetplusplus\",\n",
    "    \"deeplabv3\",\n",
    "    \"deeplabv3plus\",\n",
    "    \"fpn\",\n",
    "    \"pspnet\",\n",
    "    \"manet\",\n",
    "    \"linknet\",\n",
    "    \"pan\",\n",
    "    ]\n",
    "pytorch_encoders = [\"resnet18\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_df = pd.DataFrame([],columns=['Network', 'Architecture', 'Encoder', 'Dataset', 'IoU', 'Precision', 'Recall', 'Accuracy'])\n",
    "for pytorch_architecture, pytorch_architecture_name in zip(pytorch_architectures, pytorch_architectures_names):\n",
    "    for encoder in pytorch_encoders:\n",
    "        for dataset in list_of_datasets:\n",
    "            for loss in list_of_losses:\n",
    "                pytorch_result = pd.read_csv(pytorch_networks / (pytorch_architecture+\"_\"+encoder+\"_\"+loss+\"_\"+dataset) / \"evaluations\" / \"stats\" / \"general_stats.csv\",index_col=0)\n",
    "                pytorch_result[\"Network\"] = \"Pytorch_networks\"\n",
    "                pytorch_result[\"Architecture\"] = pytorch_architecture_name\n",
    "                pytorch_result[\"Encoder\"] = \"resnet18\"\n",
    "                pytorch_result[\"Dataset\"] = dataset\n",
    "                pytorch_df = pd.concat([pytorch_df,pytorch_result], axis=0)\n",
    "pytorch_df = pytorch_df[[\"Network\",\"Architecture\",\"Encoder\",\"Dataset\",\"Accuracy\"]]\n",
    "pytorch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valeo_row = pd.DataFrame([(\"Keras-Valeo\",\"TiledSoilingNet\",\"Resnet10\",\"Valeo internal\", 0.8735)],columns=pytorch_df.columns)\n",
    "valeo_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = pd.concat([pytorch_df,valeo_row])\n",
    "complete_df[\"Dataset\"].replace(\"all_files\",\"Woodscape\", inplace=True)\n",
    "complete_df = complete_df[[\"Architecture\",\"Encoder\",\"Dataset\",\"Accuracy\"]]\n",
    "complete_df[\"Encoder\"].replace(\"resnet18\",\"Resnet18\", inplace=True)\n",
    "complete_df[\"Architecture\"] = complete_df[\"Architecture\"].str[0].str.upper() + complete_df[\"Architecture\"].str[1:]\n",
    "complete_df.sort_values(by=\"Accuracy\", inplace=True, ascending=False)\n",
    "complete_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_datasets = [\"all_files\"]\n",
    "list_of_losses = [\"torch_cross_entropy\"]\n",
    "pytorch_architectures = [    \n",
    "    \"fpn\"\n",
    "    ]\n",
    "pytorch_encoders = [\"resnet18\", \"resnet34\", \"resnet50\", \"resnet101\", \"resnet152\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_df = pd.DataFrame([],columns=['Network', 'Architecture', 'Encoder', 'Dataset','Loss', 'IoU', 'Precision', 'Recall', 'Accuracy'])\n",
    "for pytorch_architecture in pytorch_architectures:\n",
    "    for encoder in pytorch_encoders:\n",
    "        for dataset in list_of_datasets:\n",
    "            for loss in list_of_losses:\n",
    "                pytorch_result = pd.read_csv(pytorch_networks / (pytorch_architecture+\"_\"+encoder+\"_\"+loss+\"_\"+dataset) / \"evaluations\" / \"stats\" / \"general_stats.csv\",index_col=0)\n",
    "                pytorch_result[\"Network\"] = \"Pytorch_networks\"\n",
    "                pytorch_result[\"Architecture\"] = pytorch_architecture\n",
    "                pytorch_result[\"Encoder\"] = encoder\n",
    "                pytorch_result[\"Dataset\"] = dataset\n",
    "                pytorch_result[\"Loss\"] = loss\n",
    "                pytorch_df = pd.concat([pytorch_df,pytorch_result], axis=0)\n",
    "#pytorch_df = pytorch_df[[\"Network\",\"Architecture\",\"Encoder\",\"Dataset\",\"Accuracy\"]]\n",
    "pytorch_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_datasets = [\"all_files\"]\n",
    "list_of_losses = [\"torch_cross_entropy\",\"dice_loss\",\"focal_loss\",\"rmse\"]\n",
    "pytorch_architectures = [    \n",
    "    \"fpn\"\n",
    "    ]\n",
    "pytorch_encoders = [\"resnet18\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_df = pd.DataFrame([],columns=['Architecture', 'Encoder', 'Loss', 'Dataset', 'IoU', 'Precision', 'Recall', 'Accuracy'])\n",
    "for pytorch_architecture in pytorch_architectures:\n",
    "    for encoder in pytorch_encoders:\n",
    "        for dataset in list_of_datasets:\n",
    "            for loss in list_of_losses:\n",
    "                pytorch_result = pd.read_csv(pytorch_networks / (pytorch_architecture+\"_\"+encoder+\"_\"+loss+\"_\"+dataset) / \"evaluations\" / \"stats\" / \"general_stats.csv\",index_col=0)\n",
    "                pytorch_result[\"Architecture\"] = pytorch_architecture\n",
    "                pytorch_result[\"Encoder\"] = encoder\n",
    "                pytorch_result[\"Dataset\"] = dataset\n",
    "                pytorch_result[\"Loss\"] = loss\n",
    "                pytorch_df = pd.concat([pytorch_df,pytorch_result], axis=0)\n",
    "pytorch_df = pytorch_df[[\"Architecture\",\"Encoder\",\"Loss\",\"Dataset\",\"Accuracy\"]]\n",
    "pytorch_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_datasets = [\"all_files\", \"correct_files\", \"correct_clear_files\", \"correct_clear_strict_files\"]\n",
    "dataset_sorting = {\"all_files\":0, \"correct_files\":1, \"correct_clear_files\":2, \"correct_clear_strict_files\":3}\n",
    "list_of_losses = [\"torch_cross_entropy\"]\n",
    "pytorch_architectures = [    \n",
    "    \"unet\",\n",
    "    \"fpn\",\n",
    "    \"pspnet\",\n",
    "    \"manet\",\n",
    "    \"linknet\",\n",
    "    \"pan\",\n",
    "    ]\n",
    "pytorch_architectures_names = [    \n",
    "    \"Unet\",\n",
    "    \"FPNet\",\n",
    "    \"PSPNet\",\n",
    "    \"MANet\",\n",
    "    \"LinkNet\",\n",
    "    \"Pan\",\n",
    "    ]\n",
    "pytorch_encoders = [\"resnet18\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_df = pd.DataFrame([],columns=['Architecture', 'Encoder', 'Loss', 'Dataset', 'IoU', 'Precision', 'Recall', 'Accuracy'])\n",
    "for pytorch_architecture, pytorch_architecture_name in zip(pytorch_architectures, pytorch_architectures_names):\n",
    "    for encoder in pytorch_encoders:\n",
    "        for dataset in list_of_datasets:\n",
    "            for loss in list_of_losses:\n",
    "                pytorch_result = pd.read_csv(pytorch_networks / (pytorch_architecture+\"_\"+encoder+\"_\"+loss+\"_\"+dataset) / \"evaluations\" / \"stats\" / \"general_stats.csv\",index_col=0)\n",
    "                pytorch_result[\"Architecture\"] = pytorch_architecture_name\n",
    "                pytorch_result[\"Encoder\"] = encoder\n",
    "                pytorch_result[\"Dataset\"] = dataset\n",
    "                pytorch_result[\"Loss\"] = loss\n",
    "                pytorch_df = pd.concat([pytorch_df,pytorch_result], axis=0)\n",
    "pytorch_df = pytorch_df[[\"Architecture\",\"Encoder\",\"Loss\",\"Dataset\",\"Accuracy\"]]\n",
    "pytorch_df.sort_values(by=\"Dataset\", ascending=True, inplace=True, key=lambda x: x.map(dataset_sorting))\n",
    "pytorch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14,8))\n",
    "plt.title(\"Test accuracy\")\n",
    "for pytorch_architecture in pytorch_architectures_names:\n",
    "    combination_df = pytorch_df[pytorch_df[\"Architecture\"]==pytorch_architecture]\n",
    "    plt.plot(combination_df[\"Dataset\"], combination_df[\"Accuracy\"], label = f\"{pytorch_architecture}\")\n",
    "#plt.ylim([0,1])\n",
    "plt.xlabel(\"Training set\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(\"test_accuracy_2.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_architectures = [    \n",
    "    \"unet\",\n",
    "    \"fpn\",\n",
    "    \"pspnet\",\n",
    "    \"manet\",\n",
    "    \"linknet\",\n",
    "    \"pan\",\n",
    "    ]\n",
    "pytorch_architectures_names = [    \n",
    "    \"Unet\",\n",
    "    \"FPNet\",\n",
    "    \"PSPNet\",\n",
    "    \"MANet\",\n",
    "    \"LinkNet\",\n",
    "    \"Pan\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv(\"../model_outputs/wandb_export_2.csv\")\n",
    "training_df = training_df[(training_df[\"encoder\"] ==\"resnet18\") | (training_df[\"encoder\"].isna())]\n",
    "training_df = training_df[(training_df[\"framework\"] ==\"pytorch_networks\")]\n",
    "training_df = training_df[(training_df[\"loss\"] ==\"torch_cross_entropy\")]\n",
    "training_df.drop_duplicates(subset=[\"model\",\"encoder\",\"dataset\"], inplace=True,keep=\"first\")\n",
    "training_df.sort_values(by=[\"model\",\"encoder\",\"dataset\"],ascending=True, inplace=True)\n",
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = training_df[(training_df[\"model\"].isin(pytorch_architectures))]\n",
    "training_df[\"Runtime_relative\"] = training_df[\"Runtime\"]/training_df[\"epochs\"]\n",
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14,8))\n",
    "for pytorch_architecture,pytorch_architecture_name in zip(pytorch_architectures, pytorch_architectures_names):\n",
    "    combination_df = training_df[training_df[\"model\"]==pytorch_architecture]\n",
    "    training_times = []\n",
    "    for dataset_name in list_of_datasets:\n",
    "        training_times.append(combination_df[combination_df[\"dataset\"]==dataset_name][\"Runtime_relative\"].item())\n",
    "    plt.plot(list_of_datasets, training_times, label = f\"{pytorch_architecture_name}\")\n",
    "#plt.ylim([0,1])\n",
    "plt.xlabel(\"Training set\")\n",
    "plt.ylabel(\"Training times in seconds\")\n",
    "plt.legend()\n",
    "plt.title(\"Training time per epoch\")\n",
    "plt.savefig(\"training_times_2.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
