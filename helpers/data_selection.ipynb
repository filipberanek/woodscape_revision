{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "sns.set_context(\"talk\", font_scale=1.0, rc={\"font.family\": \"serif\", \"font.serif\": [\"Computer Modern Serif\"]})\n",
    "fig_size = (16,8)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read list of files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List contains all images from dataset (5000 images). There are only asssign 3 columns to the list. \n",
    "</p>\n",
    "To be deleted - Obvious errors in annotations - Correct files\n",
    "</p>\n",
    "Unclear - Unclear boundaries between classes or simplifications - Correct clear files\n",
    "</p>\n",
    "Strict delete - Inconsistencies between images in annotations. Correct clear strict files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_file_path = r\"./filter_of_files.csv\"\n",
    "df = pd.read_csv(selection_file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this functions do binning into annotation classes per image\n",
    "\"\"\"\n",
    "def labels_binning(root_path:pathlib.Path, list_of_label_paths:list):\n",
    "    np_hist = np.zeros((256,3))\n",
    "    # Dataframe of overall stats\n",
    "    df_2 = pd.DataFrame({\n",
    "    \"Label ID\":[0,1,2,3],\n",
    "    \"Label name\":[\"Clear\", \"Transparent\", \"Semi_transparent\", \"Opaque\"],\n",
    "    \"Label pixel number\":[0,0,0,0]\n",
    "    })\n",
    "    # Dataframe for image stats\n",
    "    df_per_image = pd.DataFrame(columns= [\"Filename\", \"Clear\", \"Transparent\", \"Semi_transparent\", \"Opaque\"])\n",
    "    for file in tqdm.tqdm(list_of_label_paths):\n",
    "        lbl = np.array(Image.open(root_path / file)) #returns BGR (Blue-Green-Red)\n",
    "        values, counts = np.unique(lbl, return_counts=True)\n",
    "        clear = 0\n",
    "        transparent = 0\n",
    "        semitransparent = 0\n",
    "        opaque = 0\n",
    "        for value, count in zip(values, counts):\n",
    "            df_2.loc[df_2[\"Label ID\"]==value,\"Label pixel number\"] += count\n",
    "            if value == 0:\n",
    "                clear = count\n",
    "            elif value == 1:\n",
    "                transparent = count\n",
    "            elif value == 2:\n",
    "                semitransparent = count\n",
    "            elif value == 3:\n",
    "                opaque = count\n",
    "        one_record = pd.DataFrame.from_dict([{\n",
    "                \"Filename\":file,\n",
    "                \"Clear\":clear, \n",
    "                \"Transparent\":transparent, \n",
    "                \"Semi_transparent\":semitransparent, \n",
    "                \"Opaque\":opaque\n",
    "            }])\n",
    "        df_per_image = pd.concat([df_per_image, one_record])\n",
    "    df_per_image.set_index(\"Filename\", inplace=True)\n",
    "    df_per_image[\"Total_number_of_pixel\"] = df_per_image.sum(axis = 1)\n",
    "    list_of_column_names = [\"Clear\", \"Transparent\", \"Semi_transparent\", \"Opaque\"]\n",
    "    for column in list_of_column_names:\n",
    "        print(f\"We are processing occlusion level of {column}\")\n",
    "        df_per_image[f\"{column}_relative\"] = df_per_image[column]/df_per_image[\"Total_number_of_pixel\"]\n",
    "    return df_per_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_labels_distribution_per_image(df_stats_per_img):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    plt.hist([df_stats_per_img[\"Clear_relative\"], \n",
    "            df_stats_per_img[\"Transparent_relative\"],\n",
    "            df_stats_per_img[\"Semi_transparent_relative\"], \n",
    "            df_stats_per_img[\"Opaque_relative\"]], label = [\n",
    "                \"Clear\", \n",
    "                \"Transparent\", \n",
    "                \"Semi Transparent\", \n",
    "                \"Opaque\"\n",
    "            ])\n",
    "    plt.xlabel(\"Percentage of of image covered in bin\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(f\"Distribution of image occlusions types coverage\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_labels_distribution(df_stats_per_img):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    plt.bar(df_stats_per_img[[\"Clear\", \"Transparent\", \"Semi_transparent\", \"Opaque\"]].sum().keys(), \n",
    "            df_stats_per_img[[\"Clear\", \"Transparent\", \"Semi_transparent\", \"Opaque\"]].sum().values)\n",
    "    plt.xlabel(\"Type of occlusion\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(f\"Sum  class related pixels\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(df_stats_per_img[[\"Clear\", \"Transparent\", \"Semi_transparent\", \"Opaque\"]].sum()/df_stats_per_img[\"Total_number_of_pixel\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy all files from source to split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtLabelsPath_source = pathlib.Path(r\"../woodscape_input/gtLabels\")\n",
    "rgbImagesPath_source = pathlib.Path(r\"../woodscape_input/rgbImages\")\n",
    "rgbLabelsPath_source = pathlib.Path(r\"../woodscape_input/rgbLabels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtLabelsPath_test = pathlib.Path(r\"../woodscape_preprocessed/test/gtLabels\")\n",
    "rgbImagesPath_test = pathlib.Path(r\"../woodscape_preprocessed/test/rgbImages\")\n",
    "rgbLabelsPath_test = pathlib.Path(r\"../woodscape_preprocessed/test/rgbLabels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtLabelsPath_train = pathlib.Path(r\"../woodscape_preprocessed/train/gtLabels\")\n",
    "rgbImagesPath_train = pathlib.Path(r\"../woodscape_preprocessed/train/rgbImages\")\n",
    "rgbLabelsPath_train = pathlib.Path(r\"../woodscape_preprocessed/train/rgbLabels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create naive split by using 249 file sfrom beggining and 248 from the end. Files are sorted by names, which means we are selecting complete traces including (7-9 images per trace). There is no leak then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_df = df[df[\"Strict delete\"]!=\"nok\"]\n",
    "list_of_files_selected = selection_df[\"Filename\"].to_list()\n",
    "selection = (list_of_files_selected[:249] + list_of_files_selected[-248:])\n",
    "print(f\"Len of selection for test is {len(selection)}\")\n",
    "all_train = set(df[\"Filename\"].to_list()) - set(selection)\n",
    "print(f\"Len of selection for train is {len(all_train)}\")\n",
    "print(f\"Does test+train equals to total number of file: {(len(all_train)+len(selection))==len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy all training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtLabelsPath_train.mkdir(exist_ok=True, parents=True)\n",
    "rgbImagesPath_train.mkdir(exist_ok=True, parents=True)\n",
    "rgbLabelsPath_train.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "for selected_image_name in tqdm.tqdm(all_train):\n",
    "    shutil.copy(str(gtLabelsPath_source/selected_image_name), str(gtLabelsPath_train/selected_image_name))\n",
    "    shutil.copy(str(rgbImagesPath_source/selected_image_name), str(rgbImagesPath_train/selected_image_name))\n",
    "    shutil.copy(str(rgbLabelsPath_source/selected_image_name), str(rgbLabelsPath_train/selected_image_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate stats per bin and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats = labels_binning(gtLabelsPath_train, all_train)\n",
    "visualize_labels_distribution_per_image(train_stats)\n",
    "visualize_labels_distribution(train_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy all test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtLabelsPath_test.mkdir(exist_ok=True, parents=True)\n",
    "rgbImagesPath_test.mkdir(exist_ok=True, parents=True)\n",
    "rgbLabelsPath_test.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "for selected_image_name in tqdm.tqdm(selection):\n",
    "    shutil.copy(str(gtLabelsPath_source/selected_image_name), str(gtLabelsPath_test/selected_image_name))\n",
    "    shutil.copy(str(rgbImagesPath_source/selected_image_name), str(rgbImagesPath_test/selected_image_name))\n",
    "    shutil.copy(str(rgbLabelsPath_source/selected_image_name), str(rgbLabelsPath_test/selected_image_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate stats per bin and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stats = labels_binning(gtLabelsPath_test, selection)\n",
    "visualize_labels_distribution_per_image(test_stats)\n",
    "visualize_labels_distribution(test_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save train and test statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats.to_csv(\"train_stats.csv\")\n",
    "test_stats.to_csv(\"test_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(14,6))\n",
    "colors = [\"blue\",\"orange\",\"green\", \"red\"]\n",
    "classes = [\"Clear\", \"Transparent\", \"Semi_transparent\", \"Opaque\"]\n",
    "axs[0].bar(classes, \n",
    "        (train_stats[classes].sum().values)/1000000,color=colors)\n",
    "axs[1].bar(classes, \n",
    "        (test_stats[classes].sum().values)/1000000,color=colors)\n",
    "#axs[0].set_xlabel(\"Type of occlusion\")\n",
    "axs[0].set_ylabel(\"Pixel frequency in milions\" )\n",
    "axs[0].set_xticklabels(classes, rotation = 25)\n",
    "axs[0].set_title(f\"Sum of class related pixels for training\")\n",
    "#axs[1].set_xlabel(\"Type of occlusion\")\n",
    "axs[1].set_ylabel(\"Pixel frequency in milions\")\n",
    "axs[1].set_xticklabels(classes, rotation = 24)\n",
    "axs[1].set_title(f\"Sum of class related pixels for test\")\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"train_test_split.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create txt list of files for network training using \"Baseline set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = df[df.Filename.isin(all_train)]\n",
    "\n",
    "train_files = all_files[:3833]\n",
    "val_files = all_files[3833:]\n",
    "\n",
    "for dataset_name, dataset in zip([\"train\", \"val\"], [train_files, val_files]):\n",
    "    correct_files = []\n",
    "    file = open(gtLabelsPath_train.parent/f'{dataset_name}_all_files.txt','w')\n",
    "    for filename in dataset[\"Filename\"].to_list():\n",
    "        file.write(f\"/rgbImages/{filename},/gtLabels/{filename} \\n\")\n",
    "        correct_files.append(f\"./rgbImages/{filename},./gtLabels/{filename}\")\n",
    "    file.close()\n",
    "    print(f\"for dataset {dataset_name} there is num of files: {len(correct_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_stats = labels_binning(gtLabelsPath_train, train_files[\"Filename\"].to_list())\n",
    "visualize_labels_distribution_per_image(train_all_stats)\n",
    "visualize_labels_distribution(train_all_stats)\n",
    "val_all_stats = labels_binning(gtLabelsPath_train, val_files[\"Filename\"].to_list())\n",
    "visualize_labels_distribution_per_image(val_all_stats)\n",
    "visualize_labels_distribution(val_all_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create txt list of files for network training using \"Correct files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = df[df.Filename.isin(all_train)]\n",
    "correct_files = all_files[all_files[\"To be deleted\"].isna()]\n",
    "\n",
    "train_files = correct_files[:3148]\n",
    "val_files = correct_files[3148:]\n",
    "\n",
    "for dataset_name, dataset in zip([\"train\", \"val\"], [train_files, val_files]):\n",
    "    correct_files = []\n",
    "    file = open(gtLabelsPath_train.parent/f'{dataset_name}_correct_files.txt','w')\n",
    "    for filename in dataset[\"Filename\"].to_list():\n",
    "        file.write(f\"/rgbImages/{filename},/gtLabels/{filename} \\n\")\n",
    "        correct_files.append(f\"./rgbImages/{filename},./gtLabels/{filename}\")\n",
    "    file.close()\n",
    "    print(f\"for dataset {dataset_name} there is num of files: {len(correct_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_correct_stats = labels_binning(gtLabelsPath_train, train_files[\"Filename\"].to_list())\n",
    "visualize_labels_distribution_per_image(train_correct_stats)\n",
    "visualize_labels_distribution(train_correct_stats)\n",
    "val_correct_stats = labels_binning(gtLabelsPath_train, val_files[\"Filename\"].to_list())\n",
    "visualize_labels_distribution_per_image(val_correct_stats)\n",
    "visualize_labels_distribution(val_correct_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create txt list of files for network training using \"Correct clear files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = df[df.Filename.isin(all_train)]\n",
    "clear_mask = all_files[\"Unclear\"].isna()\n",
    "correct_mask = all_files[\"To be deleted\"].isna()\n",
    "clear_files = all_files[clear_mask & correct_mask]\n",
    "\n",
    "train_files = clear_files[:2629]\n",
    "val_files = clear_files[2629:]\n",
    "\n",
    "\n",
    "for dataset_name, dataset in zip([\"train\", \"val\"], [train_files, val_files]):\n",
    "    correct_files = []\n",
    "    file = open(gtLabelsPath_train.parent/f'{dataset_name}_correct_clear_files.txt','w')\n",
    "    for filename in dataset[\"Filename\"].to_list():\n",
    "        file.write(f\"/rgbImages/{filename},/gtLabels/{filename} \\n\")\n",
    "        correct_files.append(f\"./rgbImages/{filename},./gtLabels/{filename}\")\n",
    "    file.close()\n",
    "    print(f\"for dataset {dataset_name} there is num of files: {len(correct_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clear_stats = labels_binning(gtLabelsPath_train, train_files[\"Filename\"].to_list())\n",
    "visualize_labels_distribution_per_image(train_clear_stats)\n",
    "visualize_labels_distribution(train_clear_stats)\n",
    "val_clear_stats = labels_binning(gtLabelsPath_train, val_files[\"Filename\"].to_list())\n",
    "visualize_labels_distribution_per_image(val_clear_stats)\n",
    "visualize_labels_distribution(val_clear_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create txt list of files for network training using \"Correct clear strict files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = df[df.Filename.isin(all_train)]\n",
    "strict_delete_mask = all_files[\"Strict delete\"].isna()\n",
    "strict_files = all_files[strict_delete_mask]\n",
    "\n",
    "train_files = strict_files[:1254]\n",
    "val_files = strict_files[1254:]\n",
    "\n",
    "for dataset_name, dataset in zip([\"train\", \"val\"], [train_files, val_files]):\n",
    "    correct_files = []\n",
    "    file = open(gtLabelsPath_train.parent/f'{dataset_name}_correct_clear_strict_files.txt','w')\n",
    "    for filename in dataset[\"Filename\"].to_list():\n",
    "        file.write(f\"/rgbImages/{filename},/gtLabels/{filename} \\n\")\n",
    "        correct_files.append(f\"./rgbImages/{filename},./gtLabels/{filename}\")\n",
    "    file.close()\n",
    "    print(f\"for dataset {dataset_name} there is num of files: {len(correct_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_strict_stats = labels_binning(gtLabelsPath_train, train_files[\"Filename\"].to_list())\n",
    "visualize_labels_distribution_per_image(train_strict_stats)\n",
    "visualize_labels_distribution(train_strict_stats)\n",
    "val_strict_stats = labels_binning(gtLabelsPath_train, val_files[\"Filename\"].to_list())\n",
    "visualize_labels_distribution_per_image(val_strict_stats)\n",
    "visualize_labels_distribution(val_strict_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create txt list of files for network test using \"test all files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_df = df[df[\"Strict delete\"]!=\"nok\"]\n",
    "test_df = pd.concat([selection_df[:249], selection_df[-248:]])\n",
    "\n",
    "correct_files = []\n",
    "file = open(gtLabelsPath_test.parent/f'test_all_files.txt','w')\n",
    "for filename in test_df[\"Filename\"].to_list():\n",
    "    file.write(f\"/rgbImages/{filename},/gtLabels/{filename} \\n\")\n",
    "    correct_files.append(f\"./rgbImages/{filename},./gtLabels/{filename}\")\n",
    "file.close()\n",
    "print(f\"for dataset test there is num of files: {len(correct_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all_stats = labels_binning(gtLabelsPath_test, test_df[\"Filename\"].to_list())\n",
    "visualize_labels_distribution_per_image(test_all_stats)\n",
    "visualize_labels_distribution(test_all_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show stats of all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"blue\",\"orange\"]\n",
    "fig,axs = plt.subplots(2,2,figsize=(14,14))\n",
    "classes = [\"Clear\", \"Transparent\", \"Semi_transparent\", \"Opaque\"]\n",
    "# All data\n",
    "axs[0,0].bar(classes, \n",
    "        (train_all_stats[classes].sum().values)/1000000, label = \"train\", color = colors[0])\n",
    "axs[0,0].bar(classes, \n",
    "        (val_all_stats[classes].sum().values)/1000000, label = \"val\", color = colors[1])\n",
    "#axs[0,0].set_xlabel(\"Type of occlusion\")\n",
    "axs[0,0].set_ylabel(\"Frequency in milions\" )\n",
    "axs[0,0].set_xticklabels(classes, rotation = 25)\n",
    "axs[0,0].set_title(f\"Sum of class related pixels-Baseline set\")\n",
    "axs[0,0].set_ylim([0,2000])\n",
    "axs[0,0].legend()\n",
    "# Correct\n",
    "axs[0,1].bar(classes, \n",
    "        (train_correct_stats[classes].sum().values)/1000000, label = \"train\", color = colors[0])\n",
    "axs[0,1].bar(classes, \n",
    "        (val_correct_stats[classes].sum().values)/1000000, label = \"val\", color = colors[1])\n",
    "#axs[0,1].set_xlabel(\"Type of occlusion\")\n",
    "axs[0,1].set_ylabel(\"Frequency in milions\" )\n",
    "axs[0,1].set_xticklabels(classes, rotation = 25)\n",
    "axs[0,1].set_title(f\"Sum of class related pixels-Correct files\")\n",
    "axs[0,1].set_ylim([0,2000])\n",
    "axs[0,1].legend()\n",
    "# Clear\n",
    "axs[1,0].bar(classes, \n",
    "        (train_clear_stats[classes].sum().values)/1000000, label = \"train\", color = colors[0])\n",
    "axs[1,0].bar(classes, \n",
    "        (val_clear_stats[classes].sum().values)/1000000, label = \"val\", color = colors[1])\n",
    "#axs[1,0].set_xlabel(\"Type of occlusion\")\n",
    "axs[1,0].set_ylabel(\"Frequency in milions\" )\n",
    "axs[1,0].set_xticklabels(classes, rotation = 25)\n",
    "axs[1,0].set_title(f\"Sum of class related pixels-Correct clear files\")\n",
    "axs[1,0].set_ylim([0,2000])\n",
    "axs[1,0].legend()\n",
    "# Strict annotation\n",
    "axs[1,1].bar(classes, \n",
    "        (train_strict_stats[classes].sum().values)/1000000, label = \"train\", color = colors[0])\n",
    "axs[1,1].bar(classes, \n",
    "        (val_strict_stats[classes].sum().values)/1000000, label = \"val\", color = colors[1])\n",
    "#axs[1,1].set_xlabel(\"Type of occlusion\")\n",
    "axs[1,1].set_ylabel(\"Frequency in milions\" )\n",
    "axs[1,1].set_xticklabels(classes, rotation = 25)\n",
    "axs[1,1].set_title(f\"Sum of class related pixels-Correct clear strict files\")\n",
    "axs[1,1].set_ylim([0,2000])\n",
    "axs[1,1].legend()\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig(\"split_of_training_and_val_dataset.pdf\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
